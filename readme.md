#### MusicAnthing
## Intro
It is a multimodal model about Music. According to current plan, it will has 3 function:
- CLMP: Contrastive Language-Music Pre-training, to generate 'Synaesthesia' text from Music, but not just descriptive words
  Currently, it will firstly generate descriptive words from Music to Text using MuscisCaps[https://huggingface.co/datasets/google/MusicCaps] and then make view-related words using GPT
  After that, I am considering about create a end-to-end model from Music to Text, namely CLMP. It will use CNN to decode the Spectrograms(or MIDI) generated by BasicPitch[https://github.com/spotify/basic-pitch] and Bert to decode the text. If I can not find the dataset, I will use 'AI promt AI' to generate the view-related word to obtain dataset.(Thanks OpenAI and GPT4)
- Mus2Img  
